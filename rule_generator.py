# -*- coding: utf-8 -*-
"""rule_generator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cqRmip1O1FjhwCXurc0fc101056zpUTL
"""

import pandas as pd
from typing import Dict, Any, List
from sklearn.ensemble import RandomForestRegressor
import numpy as np

def perform_eda(df: pd.DataFrame) -> Dict[str, Any]:
    """Performs core Exploratory Data Analysis and returns a structured dictionary."""
    results = {}

    # 1. Nulls and Shape
    results['shape'] = f"{df.shape[0]} rows, {df.shape[1]} columns"

    null_summary = df.isnull().sum()
    results['null_report'] = {
        col: {"count": count, "percent": count/len(df)*100}
        for col, count in null_summary.items() if count > 0
    }

    # 2. Descriptive Stats
    numeric_df = df.select_dtypes(include=np.number)
    results['descriptive_stats'] = numeric_df.describe().to_dict()

    # 3. Correlation Matrix (Top 5 absolute correlation pairs)
    corr_matrix = numeric_df.corr().abs().unstack()
    corr_pairs = corr_matrix.sort_values(ascending=False)
    corr_pairs = corr_pairs[corr_pairs != 1.0]

    unique_pairs = []
    seen = set()
    for (feat1, feat2), corr in corr_pairs.items():
        if feat1 != feat2 and tuple(sorted((feat1, feat2))) not in seen:
            unique_pairs.append({'feat1': feat1, 'feat2': feat2, 'corr': corr})
            seen.add(tuple(sorted((feat1, feat2))))
        if len(unique_pairs) >= 5:
            break

    results['top_correlations'] = unique_pairs

    return results

def get_feature_importance(df: pd.DataFrame, target_col: str) -> List[Dict[str, Any]]:
    """Calculates feature importance using a Random Forest model."""
    if target_col not in df.columns: return []

    df_model = df.copy().select_dtypes(include=np.number).dropna()
    if target_col not in df_model.columns or df_model.shape[0] < 2: return []

    X = df_model.drop(columns=[target_col])
    y = df_model[target_col]

    if X.empty: return []

    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X, y)

    importance_list = sorted(
        [{'feature': feat, 'importance': imp} for feat, imp in zip(X.columns, model.feature_importances_)],
        key=lambda x: x['importance'],
        reverse=True
    )[:5]

    return importance_list

# rule_generator.py

from typing import Dict, Any, List
import pandas as pd
# CORRECT IMPORT: Rely on data_analyzer for statistical functions
# from data_analyzer import get_feature_importance, perform_eda # Removed this line

# --- Global Template ---
INSIGHT_TEMPLATE = {
    "executive_summary": "",
    "key_relationships": [],
    "data_quality_assessment": "",
    "strategic_recommendation": ""
}

# --- Utility Function for PDF Safety ---
def clean_for_pdf(text: str) -> str:
    """Replaces common problematic characters with safe alternatives for PDF compatibility."""
    return text.replace('•', '-') \
               .replace('—', '-') \
               .replace('“', '"') \
               .replace('”', '"') \
               .replace('’', "'") \
               .replace('‘', "'") \
               .replace('…', '...') \
               .replace(':', ' -') # Replace colon to prevent multi_cell issues

# --- Core Rule Generation Function ---
def generate_rule_based_summary(eda_results: Dict[str, Any], feature_importances: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Generates a summary based on predefined rules and statistical thresholds."""

    summary = INSIGHT_TEMPLATE.copy()

    # --- 1. Key Relationships & Findings ---
    relationships = []
    top_corr = eda_results.get('top_correlations', [])
    for pair in top_corr:
        corr_val = pair['corr']
        feat1 = pair['feat1']
        feat2 = pair['feat2']
        if corr_val >= 0.5:
            strength = "moderately strong" if corr_val < 0.8 else "extremely strong"
            relationships.append(f"An {strength} correlation ({corr_val:.2f}) exists between **{feat1}** and **{feat2}**.")

    if feature_importances:
        top_imp = feature_importances[0]
        relationships.append(f"The most impactful feature on the target column is **{top_imp['feature']}**, contributing {top_imp['importance'] * 100:.1f}% of the modeled influence.")

    summary['key_relationships'] = relationships

    # --- 2. Data Quality Assessment ---
    null_report = eda_results.get('null_report', {})
    major_null_cols = [col for col, data in null_report.items() if data.get('percent', 0) > 5.0]

    if major_null_cols:
        summary['data_quality_assessment'] = f"Significant missing values were found in: {', '.join(major_null_cols)}. **Data cleaning is necessary**."
    elif null_report:
        summary['data_quality_assessment'] = "Data quality is generally good, with only minor missing values."
    else:
        summary['data_quality_assessment'] = "No missing values were detected. Data quality is excellent."

    # --- 3. Strategic Recommendation ---
    if feature_importances:
        top_feat = feature_importances[0]['feature']
        summary['strategic_recommendation'] = f"Focus initial efforts on **{top_feat}** and its interactions, as it appears to be the primary driver of the target variable."
    elif top_corr:
         top_feat = top_corr[0]['feat1']
         summary['strategic_recommendation'] = f"Investigate **{top_feat}** to understand the underlying causal mechanism."
    else:
        summary['strategic_recommendation'] = "Proceed with visualizing marginal distributions to uncover non-linear patterns."

    # --- 4. Executive Summary ---
    sum_text = [f"Analysis of the dataset ({eda_results['shape']}) provides key insights."]
    if relationships: sum_text.append(relationships[0])
    sum_text.append(summary['data_quality_assessment'])
    summary['executive_summary'] = " ".join(sum_text)

    # --- APPLY PDF SANITIZATION ---
    summary['executive_summary'] = clean_for_pdf(summary['executive_summary'])
    summary['data_quality_assessment'] = clean_for_pdf(summary['data_quality_assessment'])
    summary['strategic_recommendation'] = clean_for_pdf(summary['strategic_recommendation'])
    summary['key_relationships'] = [clean_for_pdf(rel) for rel in summary['key_relationships']]

    return summary

# --- Q&A Function ---
def answer_question(question: str, eda_results: Dict[str, Any], feature_importances: List[Dict[str, Any]]) -> str:
    """Answers a simple question based on pre-calculated results."""
    question = question.lower()

    response_text = "I can currently only answer questions about Feature Impact, Correlations, or Data Quality."

    if "affect" in question or "impact" in question or "most important" in question:
        if feature_importances:
            top_imp = feature_importances[0]
            response_text = f"The feature that impacts the target most is **{top_imp['feature']}**, accounting for **{top_imp['importance'] * 100:.1f}%** of the modeled influence."
        else:
            response_text = "Cannot determine feature impact without selecting a numeric target column."

    elif "correlat" in question or "relationship" in question:
        top_corr = eda_results.get('top_correlations', [])
        if top_corr:
            pair = top_corr[0]
            response_text = f"The strongest linear relationship in the dataset is between **{pair['feat1']}** and **{pair['feat2']}**, with a correlation of **{pair['corr']:.2f}**."
        else:
            response_text = "No strong linear correlations were found among the numerical features."

    elif "quality" in question or "missing" in question or "null" in question:
        null_report = eda_results.get('null_report', {})
        if null_report:
            major_null_cols = [(col, data['percent']) for col, data in null_report.items() if data.get('percent', 0) > 5.0]
            if major_null_cols:
                top_null_col, top_null_perc = sorted(major_null_cols, key=lambda x: x[1], reverse=True)[0]
                response_text = f"The biggest data quality issue is missing data in **{top_null_col}** at **{top_null_perc:.2f}%**."
            else:
                response_text = "Data quality is high with no columns having critical levels of missing data."
        else:
            response_text = "The dataset appears to have excellent quality with no missing values detected."

    # Apply cleaning to the Q&A output as well
    return clean_for_pdf(response_text)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import plotly.express as px
# import numpy as np
# from fpdf import FPDF
# from typing import Dict, Any
# 
# # CORRECT IMPORTS: Pulling functions from the local modules
# # Ensure rule_generator and data_analyzer are in the same directory
# from data_analyzer import perform_eda, get_feature_importance
# from rule_generator import generate_rule_based_summary, answer_question
# 
# # --- Streamlit Configuration ---
# st.set_page_config(layout="wide", page_title="API-Free Insight Generator")
# 
# # --- PDF Generation Utility (fpdf2) ---
# # app.py (around line 18)
# class PDF(FPDF):
#     def header(self):
#         self.set_font('Helvetica', 'B', 15) # CHANGED FONT
#         self.cell(0, 10, 'Rule-Based Data Insight Report', 0, 1, 'C')
#         self.ln(5)
# 
#     # app.py (Line ~25)
#     def chapter_title(self, title):
#         self.set_font('Helvetica', 'B', 12) # Changed from Arial
#         self.cell(0, 8, title, 0, 1, 'L')
#         # ... rest of function
# 
#     # app.py (around line 32)
#     # app.py (around line 32)
#     def chapter_body(self, body):
#     # This loop filters out non-printable/unsafe characters
#         safe_body = "".join(c for c in body if 32 <= ord(c) <= 126 or c == '\n')
# 
#     # We rely on the final output encoding, but use the safe text here
#     # Use the clean_body/safe_body variable in multi_cell
#         self.set_font('Helvetica', '', 10)
#         self.multi_cell(0, 5, safe_body) # Use the sanitized text
#         self.ln()
# 
# def create_pdf_report(summary_dict: Dict[str, Any], df: pd.DataFrame) -> bytes:
#     """Generates a simple PDF from the rule-based summary dictionary."""
#     pdf = PDF()
#     pdf.add_page()
# 
#     pdf.chapter_title("1. Executive Summary")
#     pdf.chapter_body(summary_dict.get('executive_summary', 'N/A'))
# 
#     pdf.chapter_title("2. Key Relationships & Findings")
#     pdf.chapter_body("\n".join([f"- {rel}" for rel in summary_dict.get('key_relationships', ['N/A'])]))
# 
#     pdf.chapter_title("3. Data Quality Assessment")
#     pdf.chapter_body(summary_dict.get('data_quality_assessment', 'N/A'))
# 
#     pdf.chapter_title("4. Strategic Recommendation")
#     pdf.chapter_body(summary_dict.get('strategic_recommendation', 'N/A'))
# 
#     pdf.chapter_title("5. Data Snapshot")
#     pdf.chapter_body(df.head().to_string(max_rows=5, max_cols=5))
# 
#     # app.py (Line 62)
#     return pdf.output(dest='S')
# 
# # --- Streamlit UI and Orchestration ---
# 
# st.title("💡 API-Free CSV Insight Generator")
# st.markdown("*(Rule-Based Engine running locally in Colab)*")
# 
# uploaded_file = st.sidebar.file_uploader("Upload your CSV file", type=["csv"])
# 
# if uploaded_file is not None:
#     try:
#         df = pd.read_csv(uploaded_file)
#     except Exception as e:
#         st.error(f"Error loading CSV: {e}")
#         st.stop()
# 
#     # --- Session State Setup ---
#     if 'df_hash' not in st.session_state or st.session_state.df_hash != hash(uploaded_file.getvalue()):
#         st.session_state.df_hash = hash(uploaded_file.getvalue())
#         st.session_state.eda_results = perform_eda(df)
#         st.session_state.messages = []
#         st.session_state.target_col = None
# 
#     # CORRECTED LINE (now line 74 in this clean script structure)
#     numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
# 
#     # --- MAIN LAYOUT ---
#     tab_eda, tab_insights, tab_qa = st.tabs(["📊 Auto EDA & Charts", "🤖 Insight Summary", "💬 Ask Your Data"])
# 
#     # === TAB 1: Auto EDA & Charts ===
#     with tab_eda:
#         st.subheader("Raw Data Preview")
#         st.dataframe(df.head())
# 
#         st.subheader("Data Overview")
#         st.markdown(f"**Shape:** {st.session_state.eda_results['shape']}")
#         st.json(st.session_state.eda_results['null_report'])
# 
#         st.subheader("Auto-Generated Visualizations")
# 
#         # Correlation Heatmap
#         if len(numeric_cols) >= 2:
#             st.markdown("##### Feature Correlation Heatmap")
#             fig_corr = px.imshow(df[numeric_cols].corr(), text_auto=True, aspect="auto")
#             st.plotly_chart(fig_corr, use_container_width=True)
# 
#         # Target Impact Analysis setup
#         if numeric_cols:
#             st.session_state.target_col = st.selectbox("Select Target Column for Feature Importance", numeric_cols)
#             if st.session_state.target_col:
#                 importance_list = get_feature_importance(df, st.session_state.target_col)
#                 if importance_list:
#                     st.markdown(f"##### Top Features Impacting `{st.session_state.target_col}` (Random Forest)")
#                     importance_df = pd.DataFrame(importance_list)
#                     fig_imp = px.bar(importance_df, x='feature', y='importance', title=f"Feature Importance for {st.session_state.target_col}")
#                     st.plotly_chart(fig_imp)
#                 else:
#                     st.warning("Feature Importance requires at least one numerical feature besides the target.")
# 
#     # === TAB 2: Rule-Based Insight Summary ===
#     with tab_insights:
#         current_importance = []
#         if st.session_state.target_col:
#              current_importance = get_feature_importance(df, st.session_state.target_col)
# 
#         summary_dict = generate_rule_based_summary(st.session_state.eda_results, current_importance)
# 
#         st.markdown("### 📄 Automated Insight Report")
# 
#         st.info(f"**Executive Summary:** {summary_dict.get('executive_summary')}")
#         st.success(f"**Strategic Recommendation:** {summary_dict.get('strategic_recommendation')}")
# 
#         with st.expander("Detailed Report Sections"):
#             st.markdown("**Key Relationships:**")
#             for rel in summary_dict.get('key_relationships', []):
#                 st.write(f"- {rel}")
#             st.markdown(f"**Data Quality Assessment:** {summary_dict.get('data_quality_assessment')}")
# 
#         # PDF Download Button
#         pdf_bytes = create_pdf_report(summary_dict, df)
#         st.download_button(
#             label="⬇️ Download Full PDF Insight Report",
#             data=pdf_bytes,
#             file_name="Insight_Report_Rule_Based.pdf",
#             mime="application/pdf"
#         )
# 
# 
#     # === TAB 3: Ask Your Data ===
#     with tab_qa:
#         st.subheader("Ask Rule-Based Questions")
#         st.info("The Q&A uses simple rules. Ask about **Feature Impact**, **Correlations**, or **Data Quality**.")
# 
#         for message in st.session_state.messages:
#             with st.chat_message(message["role"]):
#                 st.markdown(message["content"])
# 
#         if prompt := st.chat_input("E.g., Which feature affects the target most?"):
#             st.session_state.messages.append({"role": "user", "content": prompt})
#             with st.chat_message("user"):
#                 st.markdown(prompt)
# 
#             with st.chat_message("assistant"):
#                 response_text = answer_question(
#                     prompt,
#                     st.session_state.eda_results,
#                     get_feature_importance(df, st.session_state.target_col) if st.session_state.target_col else []
#                 )
# 
#                 st.markdown(response_text)
#                 st.session_state.messages.append({"role": "assistant", "content": response_text})
# 
# else:
#     st.info("👆 Please upload a CSV file in the sidebar to begin the analysis.")